\subsection{Initialization}
\label{sec:genetic_algorithms:initialization}

  In the initialization phase of a genetic algorithm, the foundational stage is 
  set for the algorithm's evolutionary journey.
  Here, we define and setup the population of individuals to be employed in the 
  search process.
  Whether informed by prior knowledge or randomly generated, each individual's 
  evaluation is pivotal to steer the algorithm's quest for optimal solutions.

  As we delve further, stages such as selection 
  (\vref{sec:bg:ga:select}), crossover 
  (\vref{sec:bg:ga:var:cx}), and mutation (\vref{sec:bg:ga:var:mut}) build upon 
  this foundational phase.

  A GA operates on a group of individuals termed a \emph{population}.
  Determining the population's size and its initialization is crucial.
  Typically, this initialization process leans on randomness, but it can also 
  be informed by insights about the problem at 
  hand~\autocite{dasguptaComparisonMultiobjectiveEvolutionary2008}.
  
  Upon initializing the population, each individual undergoes evaluation to 
  receive a \emph{fitness value}.
  This step is imperative to glean insights about the problem, thereby directing 
  the search towards enhanced solutions.

  Using the \emph{One Max} problem as a backdrop, where there's an absence of 
  prior problem knowledge, the initialization encompasses a blind search of the 
  search space, rendering it random.
  For each population member, a random binary string of length \(n\) is 
  generated.

  Let's assume that we have a population of size 4, and that the length of the 
  binary strings is \(n = 4\).

  The initialization process could generate the following individuals:\footnote{
    Since the nature of genetic algorithms is stochastic, the initialization 
    process could generate different individuals each time the algorithm is run.
    For this example, we selected a specific set of individuals in a way that 
    makes it easier to get a grasp of the algorithm.
  }

  \begin{table}[H]
    \label{tab:genetic_algorithms:initialization:population}
    \centering
    \begin{tabular}{c|c|c}
      \multicolumn{3}{c}{\textbf{Generation 0}} \\
      \hline
      \hline
      \textbf{Individual} & \textbf{Binary string} & \textbf{Fitness} \\
      \hline
      \(I_1\) & 1100 & 2 \\
      \(I_2\) & 0001 & 1 \\
      \(I_3\) & 0000 & 0 \\
      \(I_4\) & 0100 & 1 \\
    \end{tabular}
    \caption{Population of individuals in generation 0}
  \end{table}

  \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|}
      \hline
      & \textbf{Fitness} & \textbf{Individual}  \\
      \hline
      Best & 2 & \(I_1\) \\
      Worst & 0 & \(I_3\) \\
      \hline
      \hline
      Average & \multicolumn{2}{c|}{1} \\
      \hline
      Standard deviation & \multicolumn{2}{c|}{0.817} \\
      \hline
    \end{tabular}
    \caption{Fitness of the individuals in generation 0}
    \label{tab:genetic_algorithms:initialization:population_fitness}
  \end{table}
  
  Emphasis should be placed on the aggregation functions outlined in 
  \vref{tab:genetic_algorithms:initialization:population_fitness}.
  The \emph{average fitness} is straightforward, offering an overall view of the 
  population's performance; a higher\footnote{
    Remember, a \enquote{higher fitness} refers to proximity to the optimal 
    solution, not necessarily the greatest numerical value.
  } average suggests better overall performance.
  On the other hand, the \emph{standard deviation} gauges the dispersion of 
  fitness values around this average.
  A low standard deviation indicates a homogeneous population, which might hint 
  at \textbf{premature convergence} due to limited search space exploration.
  Conversely, a high standard deviation signifies a diverse population, 
  potentially suggesting \textbf{excessive exploration} without honing in on 
  promising areas.

  The initialization phase of a genetic algorithm sets the foundation by 
  establishing the population of individuals for the search.
  This population might be randomized or informed by prior domain knowledge.
  Each member of this population undergoes a fitness evaluation, directing the 
  search towards optimal outcomes.
  Using our OMP example, we commenced with a four-individual population with 
  binary strings of length \(n = 4\), assessing their fitness.
  This foundational step paves the way for the ensuing phases of selection 
  (\vref{sec:bg:ga:select}), crossover 
  (\vref{sec:bg:ga:var:cx}), and mutation (\vref{sec:bg:ga:var:mut}).
